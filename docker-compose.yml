# cheeseshirt docker-compose
#
# CI/CD: GitHub Actions builds and pushes images to GHCR on merge to main.
#        See .github/workflows/build-and-push.yml
#
# Production deployment:
#   docker compose pull
#   docker compose up -d
#
# Local development (build from source):
#   docker compose up -d --build
#
# Note: The 'build' directives exist for local dev convenience only.
# Production should always pull pre-built images from GHCR - never build on the server.
#
# LLM Configuration:
#   The Monger talks to an LLM sidecar service. Enable ONE of:
#   - llm-openai: Uses OpenAI API (requires OPENAI_API_KEY)
#   - llm-ollama: Uses local Ollama with Phi-3.5 or other models
#
#   To switch LLMs, comment/uncomment the appropriate service below.
#   The Monger doesn't know or care which LLM is being used.

services:
  # ==========================================================================
  # LLM Sidecar - Enable ONE of these
  # ==========================================================================

  # Option 1: OpenAI (cloud API)
  llm:
    image: ghcr.io/contrived-com/cheeseshirt-llm-openai:latest
    build:
      context: ./llm-openai
      dockerfile: Dockerfile
    container_name: cheeseshirt-llm
    restart: unless-stopped
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MODEL_NAME=${LLM_MODEL:-gpt-4o}
      - DEFAULT_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - DEFAULT_MAX_TOKENS=${LLM_MAX_TOKENS:-1024}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:11435/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    networks:
      - cheeseshirt

  # Option 2: Ollama (local models - Phi-3.5, Llama, etc.)
  # Uncomment this and comment out the llm-openai service above to use local models
  # llm:
  #   image: ghcr.io/contrived-com/cheeseshirt-llm-ollama:latest
  #   build:
  #     context: ./llm-ollama
  #     dockerfile: Dockerfile
  #   container_name: cheeseshirt-llm
  #   restart: unless-stopped
  #   environment:
  #     - MODEL_NAME=${LLM_MODEL:-phi3.5}
  #     - DEFAULT_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
  #     - DEFAULT_MAX_TOKENS=${LLM_MAX_TOKENS:-1024}
  #     - LOG_LEVEL=${LOG_LEVEL:-info}
  #   volumes:
  #     # Persist downloaded models
  #     - ollama-models:/root/.ollama
  #   healthcheck:
  #     test: ["CMD", "python3", "-c", "import httpx; r = httpx.get('http://localhost:11435/health'); r.raise_for_status()"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 120s  # Model download can take a while
  #   networks:
  #     - cheeseshirt

  # ==========================================================================
  # Core Services
  # ==========================================================================

  monger:
    image: ghcr.io/contrived-com/cheeseshirt-monger:latest
    build:
      context: ./monger
      dockerfile: Dockerfile
    container_name: cheeseshirt-monger
    restart: unless-stopped
    depends_on:
      llm:
        condition: service_healthy
    environment:
      - HOST=0.0.0.0
      - PORT=3002
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_PATH=/app/logs/cheeseshirt-monger.log
      - CHARACTER_CONFIG_PATH=/app/config/monger.json
      # LLM sidecar connection
      - LLM_SERVICE_URL=http://llm:11435
      - LLM_SERVICE_TIMEOUT=120.0
    volumes:
      - ${LOG_PATH:-./logs}:/app/logs
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:3002/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - cheeseshirt

  api:
    image: ghcr.io/contrived-com/cheeseshirt-api:latest
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: cheeseshirt-api
    restart: unless-stopped
    depends_on:
      monger:
        condition: service_healthy
    environment:
      - NODE_ENV=production
      - PORT=3001
      - HOST=0.0.0.0
      - MONGER_SERVICE_URL=http://monger:3002
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_PUBLISHABLE_KEY=${STRIPE_PUBLISHABLE_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - SHIRT_PRICE_CENTS=${SHIRT_PRICE_CENTS:-3500}
      - SITE_URL=${SITE_URL:-https://cheeseshirt.com}
      - CONVERSATIONS_PATH=/app/data/conversations
      - COOKIE_SECURE=${COOKIE_SECURE:-false}
      - TIME_WASTER_THRESHOLD_HOURS=${TIME_WASTER_THRESHOLD_HOURS:-24}
      - LOG_PATH=/app/logs/cheeseshirt-api.log
      - LOG_LEVEL=${LOG_LEVEL}
    volumes:
      - ${LOG_PATH:-./logs}:/app/logs
      - ${DATA_PATH:-./data}/conversations:/app/data/conversations
    ports:
      - "127.0.0.1:3001:3001"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:3001/api/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - cheeseshirt

  web:
    image: ghcr.io/contrived-com/cheeseshirt-web:latest
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: cheeseshirt-web
    restart: unless-stopped
    ports:
      - "127.0.0.1:8080:8080"  
    depends_on:
      api:
        condition: service_healthy
    volumes:
      - ${LOG_PATH:-./logs}:/app/logs
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - cheeseshirt

  # ==========================================================================
  # Background Workers
  # ==========================================================================

  worker-stripe-orders:
    image: ghcr.io/contrived-com/cheeseshirt-worker-stripe-orders:latest
    build:
      context: ./worker-stripe-orders
      dockerfile: Dockerfile
    container_name: cheeseshirt-worker-stripe-orders
    restart: unless-stopped
    environment:
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - POLL_INTERVAL_SECONDS=${STRIPE_POLL_INTERVAL:-300}
      - ORDERS_DIR=/app/data/Orders
      - STATE_DIR=/app/data/state
      - CONVERSATIONS_DIR=/app/data/conversations
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ${DATA_PATH:-./data}/Orders:/app/data/Orders
      - ${DATA_PATH:-./data}/state:/app/data/state
      - ${DATA_PATH:-./data}/conversations:/app/data/conversations:ro
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8002/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - cheeseshirt

networks:
  cheeseshirt:
    driver: bridge

volumes:
  ollama-models:
